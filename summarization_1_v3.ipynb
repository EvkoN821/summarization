{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmuL9IXBbxGh"
   },
   "source": [
    "## Инициализация метрик оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nlyl_ci7GZbh"
   },
   "outputs": [],
   "source": [
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8H52LVsHH9f"
   },
   "outputs": [],
   "source": [
    "# pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBkVd3xQF29v",
    "outputId": "b666dde6-e561-4d83-ac36-cc6269d437bf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "def calc_rouge_scores(candidates, references, name_of_method):\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    result = {key: round(value.mid.fmeasure * 100, 1) for key, value in result.items()}\n",
    "    result[\"summarizer\"] = name_of_method\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLRrb-qJcyf_"
   },
   "outputs": [],
   "source": [
    "number_of_ex = 500 # количество примеров для оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fpop1dsG0P8_"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open(\"rouge_metrics4.csv\", \"w\") as f:\n",
    "    columns = ['rouge1','rouge2','rougeL','rougeLsum','summarizer']\n",
    "    writer = csv.DictWriter(f, fieldnames=columns)\n",
    "    writer.writeheader()\n",
    "\n",
    "def add_to_file(row):\n",
    "    with open(\"rouge_metrics4.csv\", \"a\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZ5PDydlb7Of"
   },
   "source": [
    "## Инициализация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrHpJI6RTYfY"
   },
   "outputs": [],
   "source": [
    "## первый, https://huggingface.co/datasets/IlyaGusev/gazeta\n",
    "# import json\n",
    "# \n",
    "# \n",
    "# def read_gazeta_records(file_name, shuffle=False, sort_by_date=True):\n",
    "#     assert shuffle != sort_by_date\n",
    "#     records = []\n",
    "#     with open(file_name, \"r\") as r:\n",
    "#         for line in r:\n",
    "#             records.append(json.loads(line))\n",
    "#     if sort_by_date:\n",
    "#         records.sort(key=lambda x: x[\"date\"])\n",
    "#     if shuffle:\n",
    "#         random.shuffle(records)\n",
    "#     return records\n",
    "# data = read_gazeta_records(\"gazeta_test.jsonl\")\n",
    "# data_sum = [data[i][\"summary\"] for i in range(len(data))]\n",
    "# data_text = [data[i][\"text\"] for i in range(len(data))]\n",
    "# print(f\"{data_sum = },\\n,{data_text =}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VT6U3ZwdCTJ"
   },
   "outputs": [],
   "source": [
    "## второй,  https://www.kaggle.com/datasets/thedevastator/mlsam-multilingual-summarization-dataset?select=ru_train.csv\n",
    "# import pandas as pd\n",
    "# \n",
    "# \n",
    "# df = pd.read_csv(\"ru_test.csv\", sep=',')\n",
    "# # print(df.head(1))\n",
    "# data_sum = df[\"summary\"].tolist()\n",
    "# data_text = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dBKWMLfr4UE"
   },
   "outputs": [],
   "source": [
    "### третий, https://huggingface.co/datasets/csebuetnlp/xlsum\n",
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# ds = load_dataset(\"csebuetnlp/xlsum\", \"russian\")\n",
    "# df = pd.DataFrame(ds[\"test\"])\n",
    "# data_sum = df[\"summary\"].tolist()\n",
    "# data_text = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NLqxYSC9fU-",
    "outputId": "f12d5157-da02-4a79-f8e7-e54b19ff5e53"
   },
   "outputs": [],
   "source": [
    "### четвертый, https://huggingface.co/datasets/esdurmus/wiki_lingua\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ds = load_dataset(\"esdurmus/wiki_lingua\", \"russian\")\n",
    "df = pd.DataFrame(ds[\"train\"][\"article\"])\n",
    "data_sum = df[\"summary\"].tolist()\n",
    "data_sum = [\" \".join(data_sum[i]) for i in range(len(data_sum))]\n",
    "data_text = df[\"document\"].tolist()\n",
    "data_text = [\" \".join(data_text[i]) for i in range(len(data_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ep-QqpVaVVg3",
    "outputId": "92759942-aa33-40f6-ff80-b0af1a626bb2"
   },
   "outputs": [],
   "source": [
    "print(f\"{len(data_text) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrO1uSfscR36"
   },
   "source": [
    "## реализация метода Луны\n",
    "Вычисляем значимые слова документа:\n",
    "- Делаем стемминг или лемматизацию слов: разные словоформы одной леммы должны считаться как одно слово.\n",
    "- Считаем частоты слов, формируем список слов по убыванию частоты.\n",
    "- Убираем стоп-слова: частотные слова, у которых нет отдельной смысловой нагрузки, например предлоги и частицы.\n",
    "- Убираем слишком редкие слова, например такие, которые встречаются только 1 раз, либо убираем какой-то перцентиль слов по частоте.\n",
    "- Все оставшиеся слова считаем значимыми.\n",
    "\n",
    "Считаем значимость для предложений:\n",
    "- Предложение делим на промежутки, которые начинаются и заканчиваются значимыми словами. В промежутке могут быть и незначимые слова, но не более 4 подряд.\n",
    "- Значимость промежутка — квадрат количества значимых слов в промежутке, делённый на размер промежутка.\n",
    "- Значимость предложения — максимум из значимостей промежутков.\n",
    "- Берём в качестве реферата предложения со значимостью выше определённого порога.\n",
    "\n",
    "с помощью библиотеки Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx6GrufkMWJT"
   },
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE-WBRFcNiQh"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIlo3h0rNpCB"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUnH2uR0NusN"
   },
   "outputs": [],
   "source": [
    "def luna_sum(text, limit):\n",
    "    keywords = []\n",
    "    tags = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "    doc = nlp(text.lower())\n",
    "    for token in doc:\n",
    "        if token.pos_ in tags and not(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            keywords.append(token.lemma_)\n",
    "    word_freq = Counter(keywords)\n",
    "    max_freq = Counter(keywords).most_common(1)[0][1]\n",
    "    word_freq = {word: word_freq[word] for word in word_freq if word_freq[word] != 1}\n",
    "    for word in word_freq:\n",
    "        word_freq[word] = (word_freq[word]/max_freq)\n",
    "\n",
    "    sent_power={}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.lemma_ in word_freq.keys():\n",
    "                if sent in sent_power.keys():\n",
    "                    sent_power[sent] += word_freq[word.lemma_]\n",
    "                else:\n",
    "                    sent_power[sent] = word_freq[word.lemma_]\n",
    "\n",
    "    summary = []\n",
    "    sorted_sents = sorted(sent_power.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    coef_limit = sorted_sents[limit-1][1]\n",
    "    i = 0\n",
    "    while i < len(sorted_sents) and i<limit:\n",
    "        if sorted_sents[i][1] >= coef_limit:\n",
    "            summary.append(str(sorted_sents[i][0]).capitalize())\n",
    "        i += 1\n",
    "\n",
    "    return ' '.join(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyLcCZiwcgz8"
   },
   "source": [
    "## Оценка метода Луны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z34AIkGqUvW0"
   },
   "outputs": [],
   "source": [
    "data_res_of_luna = [luna_sum(data_text[i], 4) for i in range(number_of_ex )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtacnRnHWntG",
    "outputId": "2c1e7bfb-3553-4b0a-b5c9-4cc13ddf5392"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "index_random = randint(0, number_of_ex - 1)\n",
    "print(f\"{data_text[index_random] = },\\n {data_sum[index_random] = },\\n {data_res_of_luna[index_random] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMtAGyhDSMj3",
    "outputId": "ee508ebb-7ca2-49bd-fc83-9370e9a6854c"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_luna )],data_res_of_luna, \"Luna\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAJlJS590XvW"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ECE0LNoclok"
   },
   "source": [
    "## Оценка метода TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_GJVL-tbVol"
   },
   "outputs": [],
   "source": [
    "# pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbu7laBZbY7n"
   },
   "outputs": [],
   "source": [
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCu3gi8vbdJK"
   },
   "outputs": [],
   "source": [
    "data_res_of_textRank = [summarize(data_text[i], ratio=0.2) for i in range(number_of_ex )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hbPaf8Zdh5p",
    "outputId": "92e1f81d-9b6a-4163-b08b-121c3f4f2d6d"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_textRank )], data_res_of_textRank, \"TextRank\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11pDyWrZ1NmG"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvEuhb4KfR9z"
   },
   "source": [
    "## Оценка метода - первые 3 предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "673uoUEifEF7"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0L-V4BqQetDO"
   },
   "outputs": [],
   "source": [
    "first_sent = lambda x: ' '.join(re.split(r'(?<=[.:;])\\s', x)[:3+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S59T1GjLfVJB"
   },
   "outputs": [],
   "source": [
    "data_res_of_firstSents = [first_sent(data_text[i]) for i in range(number_of_ex )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHHVA9a0flGg",
    "outputId": "aff2fea2-6094-4575-c699-c43d8ef685ca"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_firstSents )], data_res_of_firstSents, \"FirstSents\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGtgYqK91RZA"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2hTM-w9gP6Y"
   },
   "source": [
    "## Оценка mT5 - model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "https://huggingface.co/IlyaGusev/rut5_base_sum_gazeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIaCcxqQfrEU"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3f0ZxFQi3AZ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2cJT9FEi64p"
   },
   "outputs": [],
   "source": [
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jurbummkiehY"
   },
   "outputs": [],
   "source": [
    "def ruT5_base_G(text):\n",
    "  input_ids = tokenizer(\n",
    "      [text],\n",
    "      max_length=600,\n",
    "      add_special_tokens=True,\n",
    "      padding=\"max_length\",\n",
    "      truncation=True,\n",
    "      return_tensors=\"pt\"\n",
    "  )[\"input_ids\"]\n",
    "  output_ids = model.generate(\n",
    "      input_ids=input_ids,\n",
    "      no_repeat_ngram_size=4\n",
    "  )[0]\n",
    "\n",
    "  summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "  return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9gxg7v3itis"
   },
   "outputs": [],
   "source": [
    "data_res_of_ruT5_base_G = [ruT5_base_G(data_text[i]) for i in range(number_of_ex//10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMy3tu6RkXvx",
    "outputId": "2410e5e9-23ae-4d72-d4e3-37411a0cae14"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_ruT5_base_G )], data_res_of_ruT5_base_G, \"ruT5_G\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EMLTmAW1WB3"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGPzqh7qtA6h"
   },
   "source": [
    "## Оценка mT5 - MODEL_NAME = 'cointegrated/rut5-base-absum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlDzGhpFvVs7",
    "outputId": "5c68e357-50c0-46a7-82ce-f6a2391f03cd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "\n",
    "MODEL_NAME = 'cointegrated/rut5-base-absum'\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "# model.cuda();\n",
    "# model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkR8MMbjvYc_"
   },
   "outputs": [],
   "source": [
    "def ruT5_base_A(\n",
    "    text, n_words=None, compression=None,\n",
    "    max_length=1000, num_beams=3, do_sample=False, repetition_penalty=10.0,\n",
    "    **kwargs\n",
    "):\n",
    "    if n_words:\n",
    "        text = '[{}] '.format(n_words) + text\n",
    "    elif compression:\n",
    "        text = '[{0:.1g}] '.format(compression) + text\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "            **x,\n",
    "            max_length=max_length, num_beams=num_beams,\n",
    "            do_sample=do_sample, repetition_penalty=repetition_penalty,\n",
    "            **kwargs\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rchij3-MtUMb"
   },
   "outputs": [],
   "source": [
    "data_res_of_ruT5_base_A = [ruT5_base_A(data_text[i]) for i in range(number_of_ex//10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5EMzBW-tXBt"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_ruT5_base_A )], data_res_of_ruT5_base_A, \"ruT5_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InfTDWOk_vDF"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYYC7dnhQ77D"
   },
   "source": [
    "## Оценка mT5 - model_name = 'utrobinmv/t5_summary_en_ru_zh_base_2048'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pI2MrC3_Q9ej",
    "outputId": "00b5f064-0feb-4f92-b05f-1756151a329d"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "\n",
    "model_name = 'utrobinmv/t5_summary_en_ru_zh_base_2048'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWw76ZhPRVUe"
   },
   "outputs": [],
   "source": [
    "def ruT5_base_M(text):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(**input_ids)\n",
    "    result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKXyahl5RjcN",
    "outputId": "105acf16-1aaf-402c-bd56-43199d724bb3"
   },
   "outputs": [],
   "source": [
    "data_res_of_ruT5_base_M = [ruT5_base_M(data_text[i]) for i in range(number_of_ex//10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2Uzy9seRmLb"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_ruT5_base_M )], data_res_of_ruT5_base_M, \"ruT5_M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMb1__iaRrTd"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrFp_lUwSoih"
   },
   "source": [
    "## оценка модели mBART - model_name = \"IlyaGusev/mbart_ru_sum_gazeta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ziVpfI5SvV-"
   },
   "outputs": [],
   "source": [
    "from transformers import MBartTokenizer, MBartForConditionalGeneration\n",
    "\n",
    "\n",
    "model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoY0w5jZS2gI"
   },
   "outputs": [],
   "source": [
    "def mBART_base_G(text):\n",
    "    input_ids = tokenizer(\n",
    "        [text],\n",
    "        max_length=600,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        no_repeat_ngram_size=4\n",
    "    )[0]\n",
    "\n",
    "    summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzA2P_pTTF65"
   },
   "outputs": [],
   "source": [
    "data_res_of_mBART_base_G = [mBART_base_G(data_text[i]) for i in range(number_of_ex//10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a15AjCupTMZJ"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_mBART_base_G )], data_res_of_mBART_base_G, \"mBART_G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13ximoLITTas"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOyLtq_4XkBg"
   },
   "source": [
    "## Оценка ruGPT3 - G model_name = \"IlyaGusev/rugpt3medium_sum_gazeta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_skqDuEtXnbE"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_name = \"IlyaGusev/rugpt3medium_sum_gazeta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWAftijFXjvF"
   },
   "outputs": [],
   "source": [
    "def ruGPT3_G(text):\n",
    "    text_tokens = tokenizer(\n",
    "        text,\n",
    "        max_length=600,\n",
    "        add_special_tokens=False,\n",
    "        padding=False,\n",
    "        truncation=True\n",
    "    )[\"input_ids\"]\n",
    "    input_ids = text_tokens + [tokenizer.sep_token_id]\n",
    "    input_ids = torch.LongTensor([input_ids])\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        no_repeat_ngram_size=4\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(output_ids[0], skip_special_tokens=False)\n",
    "    summary = summary.split(tokenizer.sep_token)[1]\n",
    "    summary = summary.split(tokenizer.eos_token)[0]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMcYhVlFX0Ol"
   },
   "outputs": [],
   "source": [
    "data_res_of_ruGPT3_base_G = [ruGPT3_G(data_text[i]) for i in range(number_of_ex//10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0-uPC2nY2Rr"
   },
   "outputs": [],
   "source": [
    "res = calc_rouge_scores(data_sum[:len(data_res_of_ruGPT3_base_G )], data_res_of_ruGPT3_base_G, \"ruGPT3_G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUkpN7YRY8Ug"
   },
   "outputs": [],
   "source": [
    "add_to_file(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "датасет Gazeta:\n",
      "\n",
      "    rouge1  rouge2  rougeL  rougeLsum  summarizer\n",
      "0    15.2     3.6    13.8       13.7        Luna\n",
      "1    12.9     3.3    12.7       12.8    TextRank\n",
      "2    13.6     3.0    12.8       12.9  FirstSents\n",
      "3    22.0     9.7    22.0       22.0      ruT5_G\n",
      "4     9.7     0.0     9.7        9.7      ruT5_A\n",
      "5    19.9    17.0    19.9       19.9      ruT5_M\n",
      "6    19.3     6.7    19.3       19.7     mBART_G\n",
      "7     8.3     0.0     8.3        8.3    ruGPT3_G \n",
      "\n",
      "датасет MLSUM:\n",
      "\n",
      "    rouge1  rouge2  rougeL  rougeLsum  summarizer\n",
      "0     3.6     0.5     3.4        3.3        Luna\n",
      "1     3.5     0.5     3.3        3.2    TextRank\n",
      "2     2.1     0.4     2.1        2.1  FirstSents\n",
      "3     0.0     0.0     0.0        0.0      ruT5_G\n",
      "4     0.0     0.0     0.0        0.0      ruT5_A\n",
      "5    10.0     0.0    10.0       10.0      ruT5_M\n",
      "6     6.7     0.0     6.7        6.7     mBART_G\n",
      "7     0.0     0.0     0.0        0.0    ruGPT3_G \n",
      "\n",
      "датасет XLSUM:\n",
      "\n",
      "    rouge1  rouge2  rougeL  rougeLsum  summarizer\n",
      "0     4.6     2.1     4.6        4.6        Luna\n",
      "1     5.8     2.9     5.6        5.5    TextRank\n",
      "2     7.8     3.6     7.3        7.1  FirstSents\n",
      "3     8.9     0.0     8.9        8.9      ruT5_G\n",
      "4     3.3     0.0     3.3        3.3      ruT5_A\n",
      "5     5.9     0.0     5.9        5.9      ruT5_M\n",
      "6     5.4     0.0     5.4        5.4     mBART_G\n",
      "7     7.9     0.0     7.9        7.9    ruGPT3_G \n",
      "\n",
      "датасет wiki-lingua:\n",
      "\n",
      "    rouge1  rouge2  rougeL  rougeLsum  summarizer\n",
      "0     5.1     1.7     4.9        4.9        Luna\n",
      "1     6.5     1.2     6.0        6.6    TextRank\n",
      "2     3.5     0.3     3.3        3.3  FirstSents\n",
      "3     0.8     0.0     0.8        0.8      ruT5_G\n",
      "4     0.8     0.0     0.8        0.8      ruT5_A\n",
      "5     2.2     0.8     2.2        2.2      ruT5_M\n",
      "6     0.8     0.0     0.8        0.8     mBART_G\n",
      "7     1.2     0.0     1.2        1.2    ruGPT3_G\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"rouge_metrics.csv\")\n",
    "df2 = pd.read_csv(\"rouge_metrics2.csv\")\n",
    "df3 = pd.read_csv(\"rouge_metrics3.csv\")\n",
    "df4 = pd.read_csv(\"rouge_metrics4.csv\")\n",
    "print(\"\\n\\nдатасет Gazeta:\\n\\n\", df1, \"\\n\\nдатасет MLSUM:\\n\\n\", df2, \"\\n\\nдатасет XLSUM:\\n\\n\", df3, \"\\n\\nдатасет wiki-lingua:\\n\\n\", df4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
